import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from datetime import datetime, timedelta
import numpy as np
import re
from collections import defaultdict, deque
import os
from IPython.display import display, HTML
import ipywidgets as widgets
from io import StringIO, BytesIO
from matplotlib.backends.backend_pdf import PdfPages

# ========== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò –§–ê–ô–õ–ê –í NOTEBOOK ==========

def upload_file_and_create_gantt():
    """
    –ó–ê–ì–†–£–ó–ö–ê –§–ê–ô–õ–ê –ü–†–Ø–ú–û –í NOTEBOOK - –ü–û–Ø–í–ò–¢–°–Ø –ö–ù–û–ü–ö–ê –í–´–ë–û–†–ê –§–ê–ô–õ–ê
    """
    # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–∂–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
    uploader = widgets.FileUpload(
        accept='.csv,.xlsx',  # –ø—Ä–∏–Ω–∏–º–∞–µ–º CSV –∏ Excel
        multiple=False,       # —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª
        description='üìÅ –í–´–ë–ï–†–ò –§–ê–ô–õ',
        style={'description_width': 'initial'}
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    project_name = widgets.Text(
        value='–ú–æ–π –ø—Ä–æ–µ–∫—Ç',
        placeholder='–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞',
        description='–ù–∞–∑–≤–∞–Ω–∏–µ:',
        style={'description_width': 'initial'}
    )
    
    # –ö–Ω–æ–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è
    create_btn = widgets.Button(
        description='üöÄ –ü–û–°–¢–†–û–ò–¢–¨ –î–ò–ê–ì–†–ê–ú–ú–£',
        button_style='success',
        icon='rocket',
        layout=widgets.Layout(width='300px', height='40px')
    )
    
    output = widgets.Output()
    
    def on_create_click(b):
        with output:
            output.clear_output()
            
            if not uploader.value:
                print("‚ùå –°–ù–ê–ß–ê–õ–ê –í–´–ë–ï–†–ò –§–ê–ô–õ!")
                return
            
            try:
                # –ë–µ—Ä–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                uploaded_file = list(uploader.value.values())[0]
                filename = uploaded_file['name']
                content = uploaded_file['content']
                
                print(f"üìÅ –û–ë–†–ê–ë–ê–¢–´–í–ê–Æ –§–ê–ô–õ: {filename}")
                print("=" * 50)
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
                if filename.endswith('.csv'):
                    df = pd.read_csv(BytesIO(content))
                elif filename.endswith('.xlsx'):
                    df = pd.read_excel(BytesIO(content))
                else:
                    print("‚ùå –ù–ï–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ô –§–û–†–ú–ê–¢ –§–ê–ô–õ–ê")
                    return
                
                print(f"‚úÖ –§–ê–ô–õ –ó–ê–ì–†–£–ñ–ï–ù! –ó–ê–î–ê–ß: {len(df)}")
                print("\nüìä –°–û–î–ï–†–ñ–ò–ú–û–ï –§–ê–ô–õ–ê:")
                print(df)
                
                # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                os.makedirs('../figs', exist_ok=True)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                save_name = f"gantt_{timestamp}"
                save_path = f'../figs/{save_name}.png'
                pdf_path = f'../figs/{save_name}.pdf'
                
                print(f"\nüé® –°–û–ó–î–ê–Æ –î–ò–ê–ì–†–ê–ú–ú–£...")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é create_gantt_chart
                result_df = create_gantt_chart(
                    df, 
                    save_path=save_path, 
                    save_pdf=True
                )
                
                if result_df is not None:
                    print("\n‚úÖ –î–ò–ê–ì–†–ê–ú–ú–ê –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–ê!")
                    print(f"üìä PNG: {save_path}")
                    print(f"üìÑ PDF: {pdf_path}")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF
                    try:
                        with open(pdf_path, "rb") as f:
                            pdf_data = f.read()
                        
                        b64_pdf = base64.b64encode(pdf_data).decode()
                        download_html = f'''
                        <a href="data:application/pdf;base64,{b64_pdf}" 
                           download="{save_name}.pdf"
                           style="background-color: #4CAF50; color: white; padding: 10px 20px; 
                                  text-decoration: none; border-radius: 5px; display: inline-block;
                                  font-weight: bold; margin: 10px 0;">
                           üì• –°–ö–ê–ß–ê–¢–¨ PDF –û–¢–ß–ï–¢
                        </a>
                        '''
                        display(HTML(download_html))
                    except:
                        print("üí° PDF —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–ø–∫–µ ../figs/")
                
            except Exception as e:
                print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
                import traceback
                print(traceback.format_exc())
    
    create_btn.on_click(on_create_click)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    display(HTML("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 20px; border-radius: 10px; color: white; text-align: center;">
        <h1>üìä –î–ò–ê–ì–†–ê–ú–ú–´ –ì–ê–ù–¢–ê</h1>
        <p>–ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø–æ–ª—É—á–∏ –¥–∏–∞–≥—Ä–∞–º–º—É —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –ø—É—Ç–µ–º</p>
    </div>
    """))
    
    display(HTML("<h3>üìÅ –ó–ê–ì–†–£–ó–ò –§–ê–ô–õ –ü–†–û–ï–ö–¢–ê:</h3>"))
    display(uploader)
    display(project_name)
    display(create_btn)
    display(output)

# ========== –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢ ==========

def quick_upload():
    """
    –ü–†–û–°–¢–û –ó–ê–ü–£–°–¢–ò –≠–¢–£ –§–£–ù–ö–¶–ò–Æ –ò –í–´–ë–ï–†–ò –§–ê–ô–õ
    """
    print("üöÄ –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢ - –ó–ê–ì–†–£–ó–ö–ê –§–ê–ô–õ–ê")
    print("=" * 50)
    print("üìã –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: CSV, Excel")
    print("üìã –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã CSV —Ñ–∞–π–ª–∞:")
    print("""
Task,Duration,Dependencies,Workers
A,5,,2
B,3,A,1
C,4,A,3
D,2,B,2
    """)
    print()
    
    upload_file_and_create_gantt()

# ========== –¢–í–û–ô –°–£–©–ï–°–¢–í–£–Æ–©–ò–ô –ö–û–î (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô) ==========

class ProjectStructureAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    
    @staticmethod
    def detect_dependency_columns(df, task_column):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø–æ –ª–æ–≥–∏–∫–µ –ø—Ä–æ–µ–∫—Ç–∞"""
        print("üîç –ê–ù–ê–õ–ò–ó –õ–û–ì–ò–ß–ï–°–ö–û–ô –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê...")
        
        dependency_candidates = {
            'predecessors': None,
            'successors': None
        }
        
        # 1. –ê–Ω–∞–ª–∏–∑ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
        for col in df.columns:
            if col == task_column:
                continue
                
            col_data = df[col].dropna()
            if len(col_data) == 0:
                continue
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–ª–æ–Ω–∫–∏
            dependency_score = ProjectStructureAnalyzer.analyze_column_dependency_pattern(col_data, df[task_column])
            
            if dependency_score > 0.7:  # –í—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —á—Ç–æ —ç—Ç–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
                if dependency_score > dependency_candidates.get('predecessors_score', 0):
                    dependency_candidates['predecessors'] = col
                    dependency_candidates['predecessors_score'] = dependency_score
        
        print(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {dependency_candidates['predecessors']}")
        return dependency_candidates
    
    @staticmethod
    def analyze_column_dependency_pattern(column_data, task_names):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        score = 0
        total_values = len(column_data)
        task_name_set = set(task_names)
        
        if total_values == 0:
            return 0
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
        patterns_found = 0
        
        for value in column_data.head(20):  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 20 –∑–Ω–∞—á–µ–Ω–∏–π
            value_str = str(value)
            
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø–µ—Ä–≤—ã–µ –∑–∞–¥–∞—á–∏ –º–æ–≥—É—Ç –Ω–µ –∏–º–µ—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
            if pd.isna(value) or value_str in ['', 'nan', 'None']:
                patterns_found += 0.2  # –°–ª–∞–±—ã–π –ø—Ä–∏–∑–Ω–∞–∫
                continue
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∑–∞–¥–∞—á –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ –∑–∞–¥–∞—á
            if any(task in value_str for task in task_name_set if len(str(task)) > 2):
                patterns_found += 1.0  # –°–∏–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ (–∑–∞–ø—è—Ç—ã–µ, —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π)
            if re.search(r'[,;]', value_str):
                patterns_found += 0.8  # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫
            
            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–¥—ã (ID –∑–∞–¥–∞—á)
            if re.match(r'^[A-Za-z]?\d+([,;]\s*[A-Za-z]?\d+)*$', value_str.strip()):
                patterns_found += 0.6  # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫
        
        score = patterns_found / min(20, total_values)
        return score

class SmartFieldMapper:
    """–£–º–Ω—ã–π –º–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π —Å –∞–Ω–∞–ª–∏–∑–æ–º –ª–æ–≥–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    FIELD_ALIASES = {
        'Task': ['task', '–∑–∞–¥–∞—á–∞', 'activity', 'work', 'name', '–Ω–∞–∑–≤–∞–Ω–∏–µ', 'id', '–∫–æ–¥'],
        'Duration': ['duration', '–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', 'days', '–¥–Ω–µ–π', 'time', '–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'],
        'Start': ['start', 'start_date', '–Ω–∞—á–∞–ª–æ', '–¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞', 'startdate'],
        'Workers': ['workers', 'workforce', '—Ç—Ä—É–¥–æ–∑–∞—Ç—Ä–∞—Ç—ã', '—Ä–µ—Å—É—Ä—Å—ã', 'labor', '—Ä–∞–±–æ—á–∞—è —Å–∏–ª–∞', 'team'],
        'Dependencies': ['dependencies', 'predecessors', '–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏', '–ø—Ä–µ–¥—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏', 'dep', 'pred']
    }
    
    @staticmethod
    def detect_fields_with_logic(df):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–ª—è —Å —É—á–µ—Ç–æ–º –ª–æ–≥–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
        print("üéØ –£–ú–ù–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê...")
        
        # 1. –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫—É —Å –∑–∞–¥–∞—á–∞–º–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        task_column = SmartFieldMapper._find_task_column(df)
        if not task_column:
            return None
        
        print(f"   üìù –ö–æ–ª–æ–Ω–∫–∞ –∑–∞–¥–∞—á: '{task_column}'")
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        analyzer = ProjectStructureAnalyzer()
        dependencies = analyzer.detect_dependency_columns(df, task_column)
        
        # 3. –ù–∞—Ö–æ–¥–∏–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
        other_fields = SmartFieldMapper._find_other_fields(df, task_column)
        
        # 4. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        field_mapping = {
            'Task': task_column,
            **other_fields
        }
        
        # 5. –ï—Å–ª–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö
        if dependencies['predecessors']:
            field_mapping['Dependencies'] = dependencies['predecessors']
        
        # 6. –í–∞–ª–∏–¥–∏—Ä—É–µ–º –º–∞–ø–ø–∏–Ω–≥
        return SmartFieldMapper._validate_mapping(df, field_mapping)
    
    @staticmethod
    def _find_task_column(df):
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∑–∞–¥–∞—á"""
        for col in df.columns:
            col_lower = str(col).lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            for alias in SmartFieldMapper.FIELD_ALIASES['Task']:
                if alias in col_lower or col_lower in alias:
                    return col
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            if SmartFieldMapper._looks_like_task_column(df[col]):
                return col
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–µ—á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É
        for col in df.columns:
            if not pd.api.types.is_numeric_dtype(df[col]):
                return col
        
        return df.columns[0]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç - –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞
    
    @staticmethod
    def _looks_like_task_column(column):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ—Ö–æ–∂–∞ –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –Ω–∞ –∫–æ–ª–æ–Ω–∫—É —Å –∑–∞–¥–∞—á–∞–º–∏"""
        if len(column) == 0:
            return False
        
        unique_ratio = column.nunique() / len(column)
        sample_values = column.dropna().head(5)
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å –∑–∞–¥–∞—á–∞–º–∏:
        # - –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        # - –°—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # - –ù–µ –¥–∞—Ç—ã –∏ –Ω–µ —á–∏—Å–ª–∞
        
        if unique_ratio > 0.8 and not pd.api.types.is_numeric_dtype(column):
            return True
        
        return False
    
    @staticmethod
    def _find_other_fields(df, task_column):
        """–ù–∞—Ö–æ–¥–∏—Ç –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º"""
        other_fields = {}
        
        for field_type, aliases in SmartFieldMapper.FIELD_ALIASES.items():
            if field_type == 'Task':
                continue
                
            for col in df.columns:
                if col == task_column:
                    continue
                    
                col_lower = str(col).lower()
                for alias in aliases:
                    if alias in col_lower or col_lower in alias:
                        other_fields[field_type] = col
                        break
                if field_type in other_fields:
                    break
        
        return other_fields
    
    @staticmethod
    def _validate_mapping(df, field_mapping):
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ –∑–∞–¥–∞—á —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–º–µ–µ—Ç –¥–∞–Ω–Ω—ã–µ
        if field_mapping['Task'] not in df.columns:
            return None
        
        task_col = field_mapping['Task']
        if df[task_col].isna().all() or len(df[task_col].dropna()) == 0:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞–π–¥–µ–Ω—ã
        if field_mapping.get('Dependencies') and field_mapping['Dependencies'] not in df.columns:
            field_mapping['Dependencies'] = None
        
        return field_mapping

class FieldMapper:
    """–ú–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π"""
    @staticmethod
    def map_dataframe(df, field_mapping):
        rename_dict = {}
        inverse_mapping = {}
        
        for standard_field, user_field in field_mapping.items():
            if user_field and user_field in df.columns:
                rename_dict[user_field] = standard_field
                inverse_mapping[standard_field] = user_field
        
        df_mapped = df.rename(columns=rename_dict)
        return df_mapped, inverse_mapping

def validate_and_map_data(df):
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –∞–Ω–∞–ª–∏–∑–æ–º –ª–æ–≥–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    print("=" * 60)
    print("üîç –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê")
    print("=" * 60)
    
    # 1. –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π —Å –∞–Ω–∞–ª–∏–∑–æ–º –ª–æ–≥–∏–∫–∏
    field_mapping = SmartFieldMapper.detect_fields_with_logic(df)
    
    if not field_mapping:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞")
        return False, ["–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö"], df, {}
    
    print("‚úÖ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê –û–ü–†–ï–î–ï–õ–ï–ù–ê:")
    for field_type, user_field in field_mapping.items():
        if user_field:
            print(f"   ‚Ä¢ {field_type.upper()}: '{user_field}'")
    
    # 2. –ú–∞–ø–ø–∏–º DataFrame
    df_mapped, inverse_mapping = FieldMapper.map_dataframe(df, field_mapping)
    
    # 3. –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ Dependencies –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é
    if 'Dependencies' not in df_mapped.columns:
        df_mapped['Dependencies'] = ''
        print("   ‚Ä¢ DEPENDENCIES: —Å–æ–∑–¥–∞–Ω–∞ –ø—É—Å—Ç–∞—è –∫–æ–ª–æ–Ω–∫–∞")
    
    # 4. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    is_valid, errors, df_validated = standard_data_validation(df_mapped)
    
    return is_valid, errors, df_validated, inverse_mapping

def topological_sort(df):
    """–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∑–∞–¥–∞—á –ø–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º"""
    graph = {}
    for _, task in df.iterrows():
        graph[task['Task']] = parse_dependencies(task.get('Dependencies', ''))
    
    visited = set()
    result = []
    
    def visit(task):
        if task in visited:
            return
        visited.add(task)
        for dep in graph.get(task, []):
            if dep in graph:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                visit(dep)
        result.append(task)
    
    # –ù–∞—á–∏–Ω–∞–µ–º —Å –∑–∞–¥–∞—á –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    for task in graph:
        if not graph[task]:
            visit(task)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏
    for task in graph:
        if task not in visited:
            visit(task)
    
    return result

def calculate_realistic_dates(df):
    """–ü—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á —Å —É—á–µ—Ç–æ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    df = df.copy()
    
    # –ù–∞—á–∏–Ω–∞–µ–º —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã
    current_date = pd.Timestamp.now().normalize()
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç –æ–∫–æ–Ω—á–∞–Ω–∏—è –∑–∞–¥–∞—á
    task_end_dates = {}
    
    # –¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
    sorted_tasks = topological_sort(df)
    
    for task_name in sorted_tasks:
        task_idx = df[df['Task'] == task_name].index[0]
        dependencies = parse_dependencies(df.loc[task_idx, 'Dependencies'])
        duration = df.loc[task_idx, 'Duration']
        
        if not dependencies:
            # –ó–∞–¥–∞—á–∞ –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π - –Ω–∞—á–∏–Ω–∞–µ–º —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã
            start_date = current_date
        else:
            # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å—Ä–µ–¥–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            max_end_date = current_date
            for dep in dependencies:
                if dep in task_end_dates:
                    dep_end = task_end_dates[dep]
                    if dep_end > max_end_date:
                        max_end_date = dep_end
            start_date = max_end_date
        
        end_date = start_date + pd.Timedelta(days=duration)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç—ã
        df.loc[task_idx, 'Start'] = start_date
        df.loc[task_idx, 'End'] = end_date
        task_end_dates[task_name] = end_date
    
    return df

def standard_data_validation(df):
    """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    errors = []
    warnings = []
    
    print("üîç –í–ê–õ–ò–î–ê–¶–ò–Ø –î–ê–ù–ù–´–•...")
    print("=" * 50)
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞
    if df.empty:
        errors.append("–§–∞–π–ª –ø—É—Å—Ç–æ–π")
        return False, errors, df
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_columns = ['Task', 'Duration']
    for col in required_columns:
        if col not in df.columns:
            errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: '{col}'")
    
    if errors:
        return False, errors, df
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –∑–∞–¥–∞—á
    duplicate_tasks = df[df.duplicated('Task', keep=False)]
    if not duplicate_tasks.empty:
        duplicate_names = duplicate_tasks['Task'].unique()
        errors.append(f"–î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è –∑–∞–¥–∞—á: {', '.join(duplicate_names)}")
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    try:
        df['Duration'] = pd.to_numeric(df['Duration'], errors='coerce')
        invalid_durations = df['Duration'].isna() | (df['Duration'] <= 0)
        if invalid_durations.any():
            invalid_tasks = df[invalid_durations]['Task'].tolist()
            errors.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {', '.join(invalid_tasks)}")
    except Exception as e:
        errors.append(f"–û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ 'Duration': {e}")
    
    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if 'Start' in df.columns:
        try:
            df['Start'] = pd.to_datetime(df['Start'], errors='coerce', format='%Y-%m-%d')
            invalid_dates = df['Start'].isna()
            if invalid_dates.any():
                invalid_tasks = df[invalid_dates]['Task'].tolist()
                warnings.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞: {', '.join(invalid_tasks)}")
        except Exception as e:
            warnings.append(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç: {e}")
    else:
        df['Start'] = pd.Timestamp.now().normalize()
    
    # 6. –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô
    if 'Dependencies' in df.columns:
        all_tasks = set(df['Task'])
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        for _, task in df.iterrows():
            deps_str = str(task['Dependencies']) if pd.notna(task['Dependencies']) else ''
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            if re.search(r'[{}[\]()]', deps_str):
                errors.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö –∑–∞–¥–∞—á–∏ '{task['Task']}': {deps_str}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Å–ø–∏—Å–∫–µ
            if ',,' in deps_str or deps_str.startswith(',') or deps_str.endswith(','):
                errors.append(f"–ü—É—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö –∑–∞–¥–∞—á–∏ '{task['Task']}': {deps_str}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∑–∞–≤–∏—Å–∏–º—ã—Ö –∑–∞–¥–∞—á
        missing_deps = []
        for _, task in df.iterrows():
            deps = parse_dependencies(task['Dependencies'])
            for dep in deps:
                if dep and dep not in all_tasks:
                    missing_deps.append(f"'{task['Task']}' ‚Üí '{dep}'")
        
        if missing_deps:
            errors.append(f"–ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {', '.join(missing_deps)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        cycles = find_cyclic_dependencies(df)
        if cycles:
            for cycle in cycles:
                errors.append(f"–¶–∏–∫–ª–∏—á–µ—Å–∫–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: {cycle}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∞–º–æ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self_deps = []
        for _, task in df.iterrows():
            deps = parse_dependencies(task['Dependencies'])
            if task['Task'] in deps:
                self_deps.append(f"'{task['Task']}'")
        
        if self_deps:
            errors.append(f"–°–∞–º–æ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {', '.join(self_deps)}")
    
    # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    numeric_columns = ['Workers', 'Priority', 'Cost']
    for col in numeric_columns:
        if col in df.columns:
            try:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                invalid_values = df[col].isna()
                if invalid_values.any():
                    invalid_tasks = df[invalid_values]['Task'].tolist()
                    warnings.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ '{col}': {', '.join(invalid_tasks)}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                if col in ['Workers', 'Duration']:
                    negative_values = df[df[col] < 0]
                    if not negative_values.empty:
                        tasks_list = negative_values['Task'].tolist()
                        errors.append(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ '{col}': {', '.join(tasks_list)}")
            except Exception as e:
                warnings.append(f"–û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{col}': {e}")
    
    # 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∑–∞–¥–∞—á
    invalid_names = []
    for task_name in df['Task']:
        if not isinstance(task_name, str) or not task_name.strip():
            invalid_names.append(f"'{task_name}'")
        elif len(task_name.strip()) == 0:
            invalid_names.append("–ø—É—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ")
    
    if invalid_names:
        errors.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∑–∞–¥–∞—á: {', '.join(invalid_names)}")
    
    # –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –í–ê–õ–ò–î–ê–¶–ò–ò
    if warnings:
        print("‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø:")
        for warning in warnings:
            print(f"   ‚Ä¢ {warning}")
    
    if errors:
        print("‚ùå –û–®–ò–ë–ö–ò:")
        for error in errors:
            print(f"   üö´ {error}")
        return False, errors, df
    
    print("‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø –ü–†–û–ô–î–ï–ù–ê –£–°–ü–ï–®–ù–û!")
    print(f"   ‚Ä¢ –ó–∞–¥–∞—á–∏: {len(df)}")
    print(f"   ‚Ä¢ –ö–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns)}")
    print(f"   ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {df['Start'].min().strftime('%d.%m.%Y')} - {df['End'].max().strftime('%d.%m.%Y') if 'End' in df.columns else 'N/A'}")
    
    return True, errors, df

def parse_dependencies(deps_str):
    """–ü–∞—Ä—Å–∏—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    if pd.isna(deps_str) or deps_str == '' or deps_str == 'nan':
        return []
    
    try:
        clean_str = str(deps_str).replace('"', '').replace("'", "").strip()
        if not clean_str:
            return []
        
        deps = [dep.strip() for dep in clean_str.split(',')]
        return [dep for dep in deps if dep]
    except Exception:
        return []

def find_cyclic_dependencies(df):
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"""
    graph = {}
    for _, task in df.iterrows():
        graph[task['Task']] = parse_dependencies(task['Dependencies'])
    
    def dfs(task, visited, path):
        if task in visited:
            if task in path:
                cycle_start = path.index(task)
                return path[cycle_start:]
            return None
        
        visited.add(task)
        path.append(task)
        
        for neighbor in graph.get(task, []):
            if neighbor in graph:
                cycle = dfs(neighbor, visited.copy(), path.copy())
                if cycle:
                    return cycle
        
        return None
    
    all_cycles = []
    visited_global = set()
    
    for task in graph.keys():
        if task not in visited_global:
            cycle = dfs(task, set(), [])
            if cycle:
                cycle_str = ' ‚Üí '.join(cycle + [cycle[0]])
                if cycle_str not in all_cycles:
                    all_cycles.append(cycle_str)
                visited_global.update(cycle)
    
    return all_cycles

def build_dependency_graph(df):
    """–°—Ç—Ä–æ–∏—Ç –ø–æ–ª–Ω—ã–π –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    graph = {}
    for _, task in df.iterrows():
        graph[task['Task']] = {
            'dependencies': parse_dependencies(task['Dependencies']),
            'successors': []
        }
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–≤—è–∑–∏
    for task_name, task_data in graph.items():
        for dep in task_data['dependencies']:
            if dep in graph:
                graph[dep]['successors'].append(task_name)
    
    return graph

def calculate_critical_path_with_dependencies(df):
    """–ü–†–ê–í–ò–õ–¨–ù–´–ô —Ä–∞—Å—á–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—É—Ç–∏ —Å —É—á–µ—Ç–æ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    
    df = df.copy()
    df['Is_Critical'] = False
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∑–∞–¥–∞—á
    tasks_dict = {}
    for _, task in df.iterrows():
        tasks_dict[task['Task']] = {
            'duration': task['Duration'],
            'dependencies': parse_dependencies(task.get('Dependencies', '')),
            'early_start': None,
            'early_finish': None,
            'successors': []
        }
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π
    for task_name, task_data in tasks_dict.items():
        for dep in task_data['dependencies']:
            if dep in tasks_dict:
                tasks_dict[dep]['successors'].append(task_name)
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–Ω–Ω–∏—Ö —Å—Ä–æ–∫–æ–≤
    def calculate_early_times(task_name):
        if tasks_dict[task_name]['early_start'] is not None:
            return tasks_dict[task_name]['early_start'], tasks_dict[task_name]['early_finish']
        
        deps = tasks_dict[task_name]['dependencies']
        
        if not deps:
            start_date = pd.to_datetime(df[df['Task'] == task_name]['Start'].iloc[0])
        else:
            dep_finish_dates = []
            for dep in deps:
                if dep in tasks_dict:
                    _, dep_finish = calculate_early_times(dep)
                    dep_finish_dates.append(dep_finish)
            
            if dep_finish_dates:
                start_date = max(dep_finish_dates)
            else:
                start_date = pd.to_datetime(df[df['Task'] == task_name]['Start'].iloc[0])
        
        duration = tasks_dict[task_name]['duration']
        finish_date = start_date + pd.to_timedelta(duration, unit='d')
        
        tasks_dict[task_name]['early_start'] = start_date
        tasks_dict[task_name]['early_finish'] = finish_date
        
        return start_date, finish_date
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–Ω–Ω–∏–µ —Å—Ä–æ–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
    for task_name in tasks_dict.keys():
        calculate_early_times(task_name)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
    for task_name, times in tasks_dict.items():
        df.loc[df['Task'] == task_name, 'Start'] = times['early_start']
        df.loc[df['Task'] == task_name, 'End'] = times['early_finish']
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∑–¥–Ω–∏–µ —Å—Ä–æ–∫–∏ –∏ —Ä–µ–∑–µ—Ä–≤
    project_end = df['End'].max()
    
    for task_name in tasks_dict.keys():
        tasks_dict[task_name]['late_finish'] = project_end
        tasks_dict[task_name]['late_start'] = project_end - pd.to_timedelta(tasks_dict[task_name]['duration'], unit='d')
    
    # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø–æ–∑–¥–Ω–∏—Ö —Å—Ä–æ–∫–æ–≤
    for task_name in reversed(list(tasks_dict.keys())):
        successors = tasks_dict[task_name]['successors']
        if successors:
            min_late_start = min([tasks_dict[succ]['late_start'] for succ in successors])
            tasks_dict[task_name]['late_finish'] = min_late_start
            tasks_dict[task_name]['late_start'] = min_late_start - pd.to_timedelta(tasks_dict[task_name]['duration'], unit='d')
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∑–µ—Ä–≤ –≤—Ä–µ–º–µ–Ω–∏
    for task_name in tasks_dict.keys():
        tasks_dict[task_name]['float'] = (tasks_dict[task_name]['late_start'] - tasks_dict[task_name]['early_start']).days
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å - –∑–∞–¥–∞—á–∏ —Å –Ω—É–ª–µ–≤—ã–º —Ä–µ–∑–µ—Ä–≤–æ–º
    critical_tasks = [task_name for task_name, task_data in tasks_dict.items() if task_data['float'] == 0]
    
    # –û—Ç–º–µ—á–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
    if critical_tasks:
        df.loc[df['Task'].isin(critical_tasks), 'Is_Critical'] = True
        print(f"‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å: {len(critical_tasks)} –∑–∞–¥–∞—á")
        
        # –ù–∞—Ö–æ–¥–∏–º –∏ –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é —Ü–µ–ø–æ—á–∫—É –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—É—Ç–∏
        start_critical = [task for task in critical_tasks if not tasks_dict[task]['dependencies']]
        if start_critical:
            chain = [start_critical[0]]
            current_task = start_critical[0]
            
            while tasks_dict[current_task]['successors']:
                next_critical = [succ for succ in tasks_dict[current_task]['successors'] if succ in critical_tasks]
                if next_critical:
                    chain.append(next_critical[0])
                    current_task = next_critical[0]
                else:
                    break
            
            print(f"üîó –¶–µ–ø–æ—á–∫–∞: {' ‚Üí '.join(chain)}")
    
    return df

def print_detailed_analysis(df):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞"""
    critical_tasks = df[df['Is_Critical']]
    total_duration = (df['End'].max() - df['Start'].min()).days
    
    print("\n" + "="*50)
    print("üìä –ê–ù–ê–õ–ò–ó –ü–†–û–ï–ö–¢–ê")
    print("="*50)
    
    print(f"–í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(df)}")
    print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á: {len(critical_tasks)}")
    print(f"–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration} –¥–Ω–µ–π")
    print(f"–ü–µ—Ä–∏–æ–¥: {df['Start'].min().strftime('%d.%m.%Y')} - {df['End'].max().strftime('%d.%m.%Y')}")
    
    print(f"\nüî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ó–ê–î–ê–ß–ò:")
    if len(critical_tasks) > 0:
        for task in critical_tasks.itertuples():
            deps_info = f" ‚Üê {task.Dependencies}" if hasattr(task, 'Dependencies') and pd.notna(task.Dependencies) else ""
            workers_info = f" [{task.Workers}—á]" if hasattr(task, 'Workers') else ""
            print(f"   ‚Ä¢ {task.Task} - {task.Duration} –¥–Ω–µ–π{workers_info}{deps_info}")

def create_gantt_chart(df, save_path=None, save_pdf=False):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã –ì–∞–Ω—Ç–∞"""
    
    is_valid, errors, df_validated, inverse_mapping = validate_and_map_data(df)
    
    if not is_valid:
        print("‚ùå –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
        for error in errors:
            print(f"   - {error}")
        return None
    
    print("üîÑ –†–ê–°–ß–ï–¢ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ì–û –ü–£–¢–ò –ò –î–ê–¢...")
    
    # –ü—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∞—Ç—ã —Å —É—á–µ—Ç–æ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    df_with_dates = calculate_realistic_dates(df_validated)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å
    df_with_critical = calculate_critical_path_with_dependencies(df_with_dates)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—É
    print("üé® –ü–û–°–¢–†–û–ï–ù–ò–ï –î–ò–ê–ì–†–ê–ú–ú–´...")
    fig, ax = plt.subplots(figsize=(16, 10))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞
    df_sorted = df_with_critical.sort_values('Start')
    
    # –†–∏—Å—É–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É
    for i, (_, task) in enumerate(df_sorted.iterrows()):
        if task['Is_Critical']:
            color = '#e74c3c'
            alpha = 0.9
        else:
            color = '#3498db'
            alpha = 0.7
        
        # –†–∏—Å—É–µ–º –ø–æ–ª–æ—Å—É –∑–∞–¥–∞—á–∏
        ax.barh(y=task['Task'],
               left=task['Start'],
               width=task['End'] - task['Start'],
               height=0.6,
               color=color,
               alpha=alpha,
               edgecolor='white',
               linewidth=1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å —Å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
        center = task['Start'] + (task['End'] - task['Start']) / 2
        workers_info = f"({task.Workers}—á)" if hasattr(task, 'Workers') and task.Workers > 0 else ""
        ax.text(center, task['Task'], f'{int(task["Duration"])}–¥{workers_info}',
               ha='center', va='center',
               fontweight='bold', fontsize=8,
               color='white')
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞
    ax.set_xlabel('–î–∞—Ç–∞')
    ax.set_ylabel('–ó–∞–¥–∞—á–∏')
    ax.set_title('–î–ò–ê–ì–†–ê–ú–ú–ê –ì–ê–ù–¢–ê –° –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ú –ü–£–¢–ï–ú', fontweight='bold')
    ax.grid(axis='x', alpha=0.3)
    plt.xticks(rotation=45)
    
    # –õ–µ–≥–µ–Ω–¥–∞
    legend_elements = [
        Patch(facecolor='#e74c3c', alpha=0.9, label='–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å'),
        Patch(facecolor='#3498db', alpha=0.7, label='–û–±—ã—á–Ω—ã–µ –∑–∞–¥–∞—á–∏')
    ]
    ax.legend(handles=legend_elements, loc='upper right')
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    if save_path:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"üíæ –î–∏–∞–≥—Ä–∞–º–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ PDF
    if save_pdf:
        pdf_path = save_path.replace('.png', '.pdf') if save_path else 'gantt_chart.pdf'
        with PdfPages(pdf_path) as pdf:
            pdf.savefig(fig, bbox_inches='tight')
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∞–Ω–∞–ª–∏–∑–æ–º
            plt.figure(figsize=(8, 11))
            plt.axis('off')
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è PDF
            critical_tasks = df_with_critical[df_with_critical['Is_Critical']]
            total_duration = (df_with_critical['End'].max() - df_with_critical['Start'].min()).days
            
            analysis_text = f"""
–î–ò–ê–ì–†–ê–ú–ú–ê –ì–ê–ù–¢–ê - –ê–ù–ê–õ–ò–ó –ü–†–û–ï–ö–¢–ê
{'='*50}

–û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
‚Ä¢ –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(df_with_critical)}
‚Ä¢ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á: {len(critical_tasks)}
‚Ä¢ –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration} –¥–Ω–µ–π
‚Ä¢ –ü–µ—Ä–∏–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {df_with_critical['Start'].min().strftime('%d.%m.%Y')} - {df_with_critical['End'].max().strftime('%d.%m.%Y')}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ü–£–¢–¨:
"""
            for task in critical_tasks.itertuples():
                workers_info = f" ({task.Workers}—á)" if hasattr(task, 'Workers') and task.Workers > 0 else ""
                analysis_text += f"‚Ä¢ {task.Task} - {task.Duration} –¥–Ω–µ–π{workers_info}\n"
            
            analysis_text += f"\n–í–°–ï –ó–ê–î–ê–ß–ò:\n"
            for task in df_sorted.itertuples():
                deps_info = f" ‚Üê {task.Dependencies}" if hasattr(task, 'Dependencies') and pd.notna(task.Dependencies) else ""
                workers_info = f" ({task.Workers}—á)" if hasattr(task, 'Workers') and task.Workers > 0 else ""
                critical_mark = " üî¥" if task.Is_Critical else ""
                analysis_text += f"‚Ä¢ {task.Task} - {task.Duration} –¥–Ω–µ–π{workers_info}{deps_info}{critical_mark}\n"
            
            plt.text(0.1, 0.95, analysis_text, transform=plt.gca().transAxes, 
                    fontsize=9, verticalalignment='top', fontfamily='monospace')
            pdf.savefig(bbox_inches='tight')
            plt.close()
        
        print(f"üìÑ PDF –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {pdf_path}")
    
    plt.show()
    
    # –ê–Ω–∞–ª–∏–∑
    print_detailed_analysis(df_with_critical)
    
    return df_with_critical

# ========== –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´ ==========

# –ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –≤ –Ω–æ—É—Ç–±—É–∫–µ:
# quick_upload()